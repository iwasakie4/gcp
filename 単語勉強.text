ETLパイプライン
企業が抱えるビッグデータを機械学習やデータサイエンスとして分析し、ビジネスへと繋げる手法や仕組みのことです。

スナップショットデコレーター
BigQueryのバックアップ機能
レガシー SQL （legacySQL）のみサポート
分割テーブルは利用できない
過去7日以内のデータのみ復元可能


アプライアンス
特定の機能や用途に特化した専用機器を指します

gsutil cp
gsutil はストレージ操作用コマンドになります。
-zで圧縮できる

アウトバウンド・ネットワーク
ある機器やシステムから外部に向かって接続要求やデータを送ること


transfer appliance
接続の速度が遅い、信頼性が低い、ネットワークを中断する余裕がないなど、いずれの状況でも、大量データの移動は非常に大変な処理になることがあります。ネットワーク帯域幅や接続が制限されている場合は、ネットワークを介して大量のデータを転送すると接続が長時間独占されます。大規模な転送の場合は、本番環境システムのパフォーマンスに数日から数週間にわたって影響が出続ける可能性があります。Transfer Appliance を使用すると、データを Transfer Appliance にコピーしてから発送できるため、通常の業務を中断せずにデータを Google Cloud に移動できます。
Transfer Appliance のもう一つの優れたユースケースは、お客様が船やその他の現場など、リモートやモバイルの場所にいる場合です。データをローカルで収集しておき、入港したら、データを Google Cloud に発送して処理やアーカイブを行ってもらうだけで済みます。

Storage Transfer Service
Google Cloud、Amazon、Azure、オンプレミスなどにまたがるファイル ストレージとオブジェクトと間で、迅速かつ安全にデータを転送できます。

ionice 
linux コマンド ディスクIOの優先度変更

trickle
linux コマンド 帯域制限かけれる

BigQuery  ストリーミング挿入
特徴としては、他のインサートパターンよりも一般的には高速でインサートできることに加え、ジョブが完了しなくても随時参照できるというところになります。
ただしデータをBigQuery に送信してから 30 分以内の場合は、対象レコードへの Update や Delete などの DML ステートメントが利用できないようです。

BigQuery バッチロード A
PI を使用して JSON ファイルを Alteryx から BigQuery にプッシュします。

gcp cloud composer
オーケストレーション
ハイブリッド クラウドとマルチクラウド
オンプレミスとパブリック クラウドにまたがるワークフローをオーケストレートすることで、クラウドへの移行が容易になり、ハイブリッド データ環境を維持することもできます。複数のクラウドにまたがってデータ接続、処理、サービスを提供するワークフローを作成し、統一的なデータ環境を提供します。
BigQuery、Dataflow、Dataproc、Datastore、Cloud Storage、Pub/Sub、AI Platform などの Google Cloud プロダクトとのエンドツーエンドの統合により、ユーザーはパイプラインを自由かつ完全にオーケストレートできます。

directed acyclic graph 有向非巡回グラフ
閉路のない有向グラフのことである。 サイクルが存在しないため、ある頂点から同じ頂点に戻ってこれない
DAG（Direct Acyclic Graph）と呼ばれるデータ形式でジョブ同士の関係性を定義し、実行します。

gcp Cloud Speech-to-Text API
音声テキスト化

gcp Dialogflow Enterprise Edition
チャットボットから IoT デバイスまで、会話アプリはより豊かで自然なエクスペリエンスをユーザーに提供します。
ユニクロは、全世界で 約 1,900 店舗を展開する日本の先進的なアパレル小売ブランドです。同社ではモバイル アプリにチャットボットを搭載し、オンライン上だけでなく店舗でも、お客様のさまざまな質問に対応しています。現在、一部の会員向けにサービスを提供しており、ショッピングをより楽しく、シンプルにするこのチャットボットは、ユーザーの 40 % が毎週利用しています。

GCP Natural Language AI
Google の機械学習を使用して非構造化テキストから分析情報を引き出す。
Natural Language API は、テキストから構文、エンティティ、感情を検出し、テキストを事前定義された一連のカテゴリに分類します

GCP AutoML Natural Language
自社のウェブサイトに問い合わせフォームがあるとします。このフォームから毎日多くのメッセージを受け取ります。その多くはなんらかの方法で対応可能ですが、すべてのメッセージが一斉に届き、異なる従業員がいろいろなタイプのメッセージを処理するため、メッセージへの対応が遅れがちです。自動化されたシステムによってメッセージを分類し、適切な担当者が適切なコメントを見られるようになれば、非常に効率的です。

BigQuery Authorized view
利用者に対して ビューへのアクセス権限を与える が ビューの元となるテーブル自体へのアクセス権限は与えない ことにより、アクセス制御を楽にしたり、見せるデータの粒度を制御したりできる機能です。

BigQuery サイドインプット
Apache Beamでは、データ分析のためのエンリッチメントを行う際には、サイドインプットパターンが推奨されています。

Datastore は、大規模な構造化データに対して可用性の高いアクセスを必要とするアプリケーションに最適です。Datastore は、次のようなタイプのすべてのデータを保存、クエリする目的で使用できます。
- 小売店向けにリアルタイムな在庫と商品の詳細を提供する商品カタログ
- ユーザーの過去の行動と好みに応じてカスタマイズされたエクスペリエンスを提供するユーザープロフィール
- ある銀行口座から別の口座への送金など、ACID プロパティに基づくトランザクション

サブスク
定期購読など定期の意味合い


Dataprocはバックアップのmysqldumpを利用してデータ分析をおこなうために最適なサービスです。
Dataproc は、Apache Spark、Apache Flink、Presto をはじめ、30 以上のオープンソース ツールやフレームワークを実行するための、フルマネージドでスケーラビリティの高いサービスです。
Dataproc を使用すれば、データレイクのモダナイゼーション、ETL、安全なデータ サイエンスを、Google Cloud と完全に統合された極めてスケーラブルな環境で、低コストで実現できます。
ダンプしたファイルをCloud Storageに保存することで、Dataprocにインポートをすることが可能になります。


アドホック
特定の、特別の 限定目的のための

Cloud Bigtableは、最大 99.999% の可用性で大規模な分析ワークロードにも運用ワークロードにも対応できる、フルマネージドでスケーラブルな NoSQL データベース サービスです。
Cloud Bittableでは、センサーデータなどの時系列データの保存にも適しています。
行数が多く（背が高く）カラム数の少ない（幅の狭い）テーブルでは、1行あたりのイベント数が少なく、1つのイベントだけということもあり得ますが、背が低く幅の広いテーブルでは、1行あたりのイベント数が多くなります。
時系列データには、一般的に背の高いテーブルと幅の狭いテーブルを使用する必要があります。
これは、1 行に 1 つのイベントを格納することで、データに対するクエリの実行が容易になるためです。
ナローテーブル = 縦に長い
ワイドテーブル = 横に長い


Cloud DLPは、Cloud Storage、BigQuery、Cloud Datastoreの機密データのスキャンと分類をネイティブにサポートし、ストリーミングコンテンツAPIにより、追加のデータソース、カスタムワークロード、アプリケーションへのサポートを可能にします。
クラウドデータロスプリベンション（DLP）は、データセキュリティとプライバシーのレイヤーを追加してデータワークロードに組み込むことにより、機密データを保護することができます。


ハイブリッドクラウドとは、相互に情報を共有し、特定のビジネスまたは組織向けに統一された一連のアプリケーションを実行する 2 つ以上のコンピューティング環境を組み合わせたものです。次のような環境が含まれます。
1つ以上のプライベートクラウドと 1 つ以上のパブリッククラウド
2つ以上のプライベートクラウド
2つ以上のパブリッククラウド
1つ以上のクラウドに接続された 1 つのベアメタル (物理ハードウェア) 環境または仮想環境

シャーディングとは
シャーディングとはデータベースの負荷分散方法の1種で、水平分割とも呼ばれています。 同じテーブルを複数のデータベースに用意し、1つのテーブルに保存していたレコードを分散する事で各データベース内に保持されるレコードの量をへらす負荷分散の方法です。処理速度が遅いブロックチェーンなどにも使われていて今注目されている技術です。

パーティショニングは、データベースにおけるテーブル内のデータを分割して保持する機能です
パーティショニングは、データの特性や利用目的に応じて分割条件の設計が必要です。データはその条件に従って分割したテーブルに格納されますが、アプリケーションからは1つのテーブルとして扱うことができます。パーティショニングのイメージを以下に示します。

ロジスティク回帰
ロジスティック回帰分析は、いくつかの要因（説明変数）から「2値の結果（目的変数）」が起こる確率を説明・予測することができる統計手法です。
2値とは、試験の合格／不合格のように答えが2つしかない値のことを言います。


線形回帰は、別の関連する既知のデータ値を使用して未知のデータの値を予測するデータ分析手法

リカレントニューラルネットワーク (Recurrent Neural Network: RNN) は、過去の情報を利用して現在および将来の入力に対するネットワークの性能を向上させる、ディープラーニングネットワーク構造です。RNN の特徴は、ネットワークに隠れ状態とループが含まれる点です。ネットワークにループ構造を用いると、過去の情報を隠れ状態で保存し、シーケンスで処理することができます。


ニューラルネットワークとは、層状構造が人間の脳内にあるニューロンのネットワーク構造に類似した数理モデルです。ニューロンと呼ばれる相互に結合する処理要素を特徴としており、出力機能を生成します。ニューラルネットワークは、入力層と出力層で構成されており、その多くには隠れ層があります。この隠れ層は、入力を出力層で使用できるものに変換するユニットで構成されています

「回帰分析」は、結果となる数値と要因となる数値の関係を調べて、それぞれの関係を明らかにする統計的手法です。このとき、要因となる数値を「説明変数」、結果となる数値を「被説明変数」といい、「説明変数」が1つの場合を「単回帰分析」、複数の場合を「重回帰分析」といいます。
単回帰単回帰の計算式
y=a+bx
重回帰重回帰の計算式
y= a+b1x1+b2x2P+....bnxn
の式（回帰式）で表されます。

プリエンプティブ方式は、プリエンプションとも呼ばれ、実行中のタスクを中断しながら、別のタスクにCPUを割り当てて処理を行う方式です

プリエンプティブル VM インスタンスは、標準 VM の料金よりもはるかに低価格（60～91% 割引）で利用できます。
ただし、他のタスクがリソースを再利用する必要がある場合、Compute Engine がこのインスタンスを停止（プリエンプト）する可能性があります。

訓練データ (train_data)
モデルが賢くなるために使うデータ

検証データ (validation_data)
ハイパーパラメータを調整するために使うデータ

テストデータ (test_data)
学習済モデルの汎用性を評価するために使うデータ

汎化能力: 未知のデータ(訓練に使ってないデータ)に対する正しい値を予測する能力。

過剰適合: 訓練データはめっちゃ正確に予測できるけど新しいデータはてんでダメという状態。

適合不足: 訓練データすらちゃんと予測できてないという状態。

非正規形
正規化がまったく行われておらず、1行の中に複数の繰り返し項目が存在するようなテーブルは非正規形と呼びます。
イメージはエクセルで縦に結合したり同じカラムが複数あって横に長くなっていること


Cloud Dataprep は Google Cloud （GCP）に内包されているデータクレンジングサービスです。構造化データと非構造化データを視覚的に探索し、簡単にクレンジング処理を行うことができます。
データクレンジングとは、その名前の通り「データをクレンジング（洗浄）すること」を意味する言葉です。データクリーニングという名称が使われることもあります。つまり、自社が保有するデータを綺麗な形に整えることがデータクレンジングの目的です。
入力フォーマット
Cloud Dataprep への入力は以下のフォーマットに対応しています。

CSV
Excel
JSON
Plain Text
Avro
BigQuery
UTF

出力フォーマット
Cloud Dataprep からの出力は以下のフォーマットに対応しています。

CSV
JSON
Avro



Pub/Subでは、一貫したスループットが維持されているのであるならば、ある期間中の処理されていないメッセージや、サブスクリプションされたメッセージ数は一定になります。
それらの値が増加することは、パフォーマンスに関する問題が発生しているということになるため、アラートを設定することが有効です。また、一定の処理をし続けているコンピューティングリソースは、インスタンス / ストレージ / 使用済みバイトも定常的になると考えられます。
それらの値が減少するということは、コンピューティングリソースがメッセージの処理を十分に行えていないということになるため、減少を検知するアラートを設定することが有効です。
Pub/Sub は、非同期のメッセージング サービスです。
イベントを生成するサービスと、イベントを処理するサービスを分離します。
メッセージ指向のミドルウェア、またはストリーミング分析用のイベントの取り込みと配信のパイプラインとして使用できます。

Apache KafkaもPub/Subと同様のメッセージングソリューションで、トピックベースで過去のデータに遡ることができます。
しかし、Pub/Subは最大で30日間のデータ保持が可能であり、メッセージの順序指定も可能であります。
更に、Pub/Subはマネジメントサービスのため、インフラストラクチャの管理が不要です。
一方で、KafkaはGoogle Cloud上でカスタムVMによるホスティングが必要です。



Cloud SQL インスタンスは高可用性（HA）構成をとることができます。
インスタンスまたはゾーンで障害が発生した場合、永続ディスクはスタンバイ インスタンスにアタッチされ、新しいプライマリ インスタンスになります。
HA 構成は「クラスタ」とも呼ばれ、データの冗長性を確保します。
リージョン インスタンスはプライマリ インスタンスとスタンバイ インスタンスで構成されます。
各ゾーンの永続ディスクへの同期レプリケーションにより、トランザクションが commit されたとしてレポートされる前に、プライマリ インスタンスへの書き込みのすべてが両方のゾーンのディスクに複製されます。
インスタンスまたはゾーンで障害が発生した場合、永続ディスクはスタンバイ インスタンスにアタッチされ、新しいプライマリ インスタンスになります。
ユーザーは新しいプライマリに再転送されます。
このプロセスは、フェイルオーバーと呼ばれます。

Cloud SQLは、最大64個のプロセッサーコアと400GB以上のRAMを追加することで簡単にスケールアップでき、最大30TBのストレージをサポートします。

Dataflowにおいて、非グローバルウィンドウ関数もしくは非デフォルト関数を使用すると、エラーが発生する。
今回のケースであればグローバルウィンドウ関数を使用する必要があります。


Dataflowジョブは、二つの方法で停止することが可能です。
- ジョブをキャンセルする：
この方法は、ストリーミング パイプラインとバッチ パイプラインの両方に適用されます。ジョブをキャンセルすると、Dataflow サービスはバッファデータなどのデータの処理を停止します。
- ジョブをドレインする：
この方法は、ストリーミング パイプラインにのみ適用されます。ジョブをドレインすると、Dataflow サービスはバッファ内のデータの処理を完了すると同時に、新しいデータの取り込みを中止できます。
今回の場合は、Drainオプションを使用することで、バッファ内のデータ処理を確実に終了し、新しいパイプラインに切り替えることが可能です。

Dataflow は Google Cloud(GCP)に内包されている ETL ツールであり、サーバーレスかつフルマネージドのデータ処理サービスです。
Dataflow は「 Apache Beam （オープンソースのフレームワーク）」で構築されたパイプライン処理を実行できるプラットフォーム

ETL とは？
ETL とは「 Extract （抽出）、 Transform （変換）、 Load （書き出し）」の略であり、企業内のあらゆるシステムからデータを抽出し、共有する機能を搭載したツールです。

サブスクライバーとは、メール等での定期的な案内の送信を承諾しているユーザーのこと


BigtableはNoSQL型のデータベースです。
パフォーマンスに影響を与える可能性がある要因を正確に監視することで、スケールアップを適切に行うことができます。
書き込み操作レイテンシーは、Bigtableのパフォーマンスを表すメトリクスになります。
このメトリクスが継続的に増加しているということは、既存のキャパシティーでは書き込み処理を維持することができないということです。
ストレージ使用率も重要なメトリクスです。
Bigtableのストレージ容量は、ストレージ タイプとクラスタ内のノード数によって決まります。
クラスタに保存されるデータ量が増加すると、Bigtable はクラスタ内のすべてのノードにデータを分散してストレージを最適化します。
データを継続的に保存し続けるためには、使用率が増大していることはいち早く検知する必要があります。

データセットを使用した教師あり学習による顔認識はニューラルネットワークの一種である畳み込みネットワーク (CNN：Convolutional Neural Network)によって実現可能です。
CNNは画像認識に適した手法です。
ディープラーニングの研究の中で最も進められている画像認識、物体検出、領域推定などの画像分野で活用されています。

高速のネットワーク接続を使用している場合は、gsutil -m（マルチスレッド / マルチ処理）オプションを利用することで、大量のファイルを迅速に転送できます。
ただし、一部のファイルのダウンロードが失敗していても、gsutil ではどのファイルが正常にダウンロードされたかを追跡しません。
たとえば、マルチスレッド転送を利用して 100 ファイルをダウンロードし、そのうち 3 ファイルのダウンロードが失敗した場合、どの転送が失敗したかを判別して転送を再試行する処理は、スクリプト側で行う必要があります。
こうしたケースは、前述のように定期的にチェックと実行を行うことで対応できます。


もう一つの方法は、複数のファイルをアーカイブし一つのファイルにまとめることです。
確かにgsutilで直接tarを使うことはできませんが、Cloud Storageにtarファイルをロードし、LinuxでCompute Engineインスタンスにファイルを移動し、tarでファイルを分割してCloud Storageにコピーし直すことが可能です。
多くのファイルを大きなtarでバッチ処理することで、Cloud Storageのスループットが向上する。


Dataproc は、Apache Hadoop および Hadoop 分散ファイル システム（HDFS）と統合されています。
DataprocとGCSをGoogle Cloud Storageのコネクタで接続すると、クラスタの寿命が来た後もデータを保存することができます。
Dataproc はストレージに Hadoop 分散ファイル システム（HDFS）を使用する。
また、HDFS 互換の Cloud Storage コネクタが自動的にインストールされるため、HDFS と並行して Cloud Storage も使用できます。
クラスタに対してデータの移動を行うには、HDFS や Cloud Storage へのアップロードとダウンロードを使用する。

グローバルで発生する入札イベントをスケーラブルな方法で集約する方法が必要です。
Cloud Pub/Subでメッセージを発行し、Dataflowで消費することで、イベント発生時のタイムスタンプに基づいて、メッセージをデキューすることが可能になります。
また、他のソリューションと比べてもスケーラブルでコスト効率が良い方法です。

重複排除は一般に、システムと BigQuery 間のネットワーク エラーや BigQuery の内部エラーといった特定のエラー状態でストリーミング挿入の状態を判断する方法がない分散システムでの再試行シナリオで必要です。
一方で、BigQuery の重複排除はベスト エフォート型であり、データの重複がないことを保証するメカニズムとしての使用には適していません。
さらに、データの高い信頼性と可用性を保証するために、BigQuery はベスト エフォート型の重複排除の品質を低下させる可能性があります。
ストリーミングの実行後に重複行が残らないようにするには、次の手動プロセスを使用する。
- テーブル スキーマ内の列として insertId を追加し、各行のデータに insertId 値を含めます。
- ストリーミングが停止した後に、クエリを実行して重複をチェックする。
- 重複を排除するには、次のクエリを実行する。宛先テーブルを指定し、サイズの大きい結果を許容し、結果のフラット化を無効にする。

#standardSQL

SELECT
* EXCEPT（row_number）
FROM （
SELECT
*,
ROW_NUMBER（）
OVER （PARTITION BY ID_COLUMN） row_number
FROM
`TABLE_NAME
）
WHERE
row_number = 1


ODBC
Open Database Connectivity
アプリケーションソフトがデータベース管理システム（DBMS）などに接続し、データの取得や書き込み、操作などを行う方法の標準を定めたもの


BigQuery標準SQLクエリではレガシーSQLで定義されたビューを参照することができません。
DBC接続で接続するために、標準SQLを使用してevents_partitionedテーブル上に新しいビューを作成する必要があります。
また、ODBCドライバはこの際にBigQueryのロールが必要になります。

確認応答期限が切れる前にメッセージの確認応答を行わないと、Pub/Sub によってメッセージが再送信されます。
その結果、Pub/Sub によって重複するメッセージが送信されることがあります。
Google Cloud のオペレーション スイートを使用して、expiredレスポンス コードで確認応答オペレーションをモニタリングし、この状態を検出する。
このデータを取得するには、確認応答メッセージ オペレーション指標を選択し、response_code ラベルでグループ化するかフィルタする。


データセット レベルの権限により、特定のデータセット内のテーブル、ビュー、テーブルデータにアクセスできるユーザー、グループ、サービス アカウントが決まります。
たとえば、あるユーザーに特定のデータセットに対する bigquery.dataOwner Identity and Access Management（IAM）ロールを付与した場合、そのユーザーはそのデータセット内のテーブルとビューを作成、更新、削除できます。



データセットは、特定のプロジェクト内に含まれています。データセットは、テーブルとビューへのアクセスを整理して制御するために使用される最上位のコンテナです。テーブルまたはビューはデータセットに属していなければなりません。したがって、データを BigQuery に読み込む前に、1 つ以上のデータセットを作成する必要があります。


BigQuery にデータを読み込んだ後、Cloud Storageなどに、さまざまな形式でデータをエクスポートできます。
BigQuery は最大 1 GB のデータを 1 つのファイルにエクスポートできます。
1 GB を超えるデータをエクスポートする場合は、データを複数のファイルにエクスポートする必要があります。
データを複数のファイルにエクスポートすると、さまざまなサイズのファイルになります。


クラスタ化
クラスタリングとは、同じ構成の複数のコンピュータを相互接続し、外部に対して全体で一台のコンピュータであるかのように振る舞わせること

クラスタリングは、フィルタ句を使用するクエリやデータを集計するクエリなど、特定のタイプのクエリのパフォーマンスを向上させることができます。
クエリジョブまたは読み込みジョブによってデータがクラスタ化テーブルに書き込まれると、BigQuery はクラスタリング列の値を使用してデータを並べ替えます。
これらの値は、BigQuery ストレージ内の複数のブロックにデータを整理するために使用されます。
クラスタリング列に基づいてデータをフィルタする句を含むクエリを送信すると、BigQuery は並べ替えられたブロックを使用して不要なデータのスキャンを省略します。

Dataproc クラスタを作成するときは、クラスタを設定した直後に Dataproc が Dataproc クラスタ内のすべてのノードで実行する初期化アクションとして実行可能ファイルまたはスクリプトを指定できます。
初期化アクションは、ジョブの実行時に依存関係をインストールしなくてもジョブをクラスタに送信できるよう、Python パッケージのインストールなど、ジョブの依存関係を設定するために多く用いられます。


シンクは Cloud Logging に入ってきたログの振り分けをするコンポーネントです。

API を通じて Cloud Logging に入ってきたログは、シンクによって宛先であるログバケットや BigQuery などに振り分けられます。

シンクを作成した際、振り分け先が「そのシンクが所属するプロジェクトのログバケット 以外 」だった場合、 書き込み ID (Writer Identity) と呼ばれるサービスアカウントが生成されます。

書き込み ID はシンクを作成するごとに一意に生成されます。

シンクにはレベルがあり、プロジェクト、フォルダ、組織レベルと言ったものをつくれる

集約シンクは、組織またはフォルダに含まれる Google Cloud リソースからのログエントリを結合してルーティングします。
たとえば、組織に含まれるすべてのフォルダの監査ログエントリを集約し、Cloud Storage バケットに転送できます。
集約シンク機能がないと、シンクは、シンクが作成された正確なリソース（Google Cloud プロジェクト、組織、フォルダ、請求先アカウント）からのログエントリのルーティングに限定されます。


Cloud Spanner データベースは、1 つ以上のテーブルを含むことができます。
テーブルは行、列、値という構造を持ち、主キーを備えている点で、リレーショナル データベース テーブルに似ています。
主キーを選択する上で重要な点は、ホットスポットを回避するという点です。
単調増加する値やエポックタイムなどは、ホットスポットを発生させる可能性があるため不適切です。
代わりに、キーのハッシュ値やUUIDなどのランダムな値を用いることは、ベストプラクティスです。

BigQueryのDMLは、1つのジョブでテーブル内の任意の数の行を挿入、更新、削除することをサポートしています。



2020年3月までは、DML(delete merge upudateなど)の１日あたりの上限がありましたが、それ以降は上限が撤廃されました。
これによって、今回のような1時間に数千回データ更新がある場合でもDMLを用いてパフォーマンスを最大化することが可能です。
































