ETLパイプライン
企業が抱えるビッグデータを機械学習やデータサイエンスとして分析し、ビジネスへと繋げる手法や仕組みのことです。

スナップショットデコレーター
BigQueryのバックアップ機能
レガシー SQL （legacySQL）のみサポート
分割テーブルは利用できない
過去7日以内のデータのみ復元可能


アプライアンス
特定の機能や用途に特化した専用機器を指します

gsutil cp
gsutil はストレージ操作用コマンドになります。
-zで圧縮できる

アウトバウンド・ネットワーク
ある機器やシステムから外部に向かって接続要求やデータを送ること


transfer appliance
接続の速度が遅い、信頼性が低い、ネットワークを中断する余裕がないなど、いずれの状況でも、大量データの移動は非常に大変な処理になることがあります。ネットワーク帯域幅や接続が制限されている場合は、ネットワークを介して大量のデータを転送すると接続が長時間独占されます。大規模な転送の場合は、本番環境システムのパフォーマンスに数日から数週間にわたって影響が出続ける可能性があります。Transfer Appliance を使用すると、データを Transfer Appliance にコピーしてから発送できるため、通常の業務を中断せずにデータを Google Cloud に移動できます。
Transfer Appliance のもう一つの優れたユースケースは、お客様が船やその他の現場など、リモートやモバイルの場所にいる場合です。データをローカルで収集しておき、入港したら、データを Google Cloud に発送して処理やアーカイブを行ってもらうだけで済みます。

Storage Transfer Service
Google Cloud、Amazon、Azure、オンプレミスなどにまたがるファイル ストレージとオブジェクトと間で、迅速かつ安全にデータを転送できます。

ionice 
linux コマンド ディスクIOの優先度変更

trickle
linux コマンド 帯域制限かけれる

BigQuery  ストリーミング挿入
特徴としては、他のインサートパターンよりも一般的には高速でインサートできることに加え、ジョブが完了しなくても随時参照できるというところになります。
ただしデータをBigQuery に送信してから 30 分以内の場合は、対象レコードへの Update や Delete などの DML ステートメントが利用できないようです。

BigQuery バッチロード A
PI を使用して JSON ファイルを Alteryx から BigQuery にプッシュします。

gcp cloud composer
オーケストレーション
ハイブリッド クラウドとマルチクラウド
オンプレミスとパブリック クラウドにまたがるワークフローをオーケストレートすることで、クラウドへの移行が容易になり、ハイブリッド データ環境を維持することもできます。複数のクラウドにまたがってデータ接続、処理、サービスを提供するワークフローを作成し、統一的なデータ環境を提供します。
BigQuery、Dataflow、Dataproc、Datastore、Cloud Storage、Pub/Sub、AI Platform などの Google Cloud プロダクトとのエンドツーエンドの統合により、ユーザーはパイプラインを自由かつ完全にオーケストレートできます。

directed acyclic graph 有向非巡回グラフ
閉路のない有向グラフのことである。 サイクルが存在しないため、ある頂点から同じ頂点に戻ってこれない
DAG（Direct Acyclic Graph）と呼ばれるデータ形式でジョブ同士の関係性を定義し、実行します。

gcp Cloud Speech-to-Text API
音声テキスト化

gcp Dialogflow Enterprise Edition
チャットボットから IoT デバイスまで、会話アプリはより豊かで自然なエクスペリエンスをユーザーに提供します。
ユニクロは、全世界で 約 1,900 店舗を展開する日本の先進的なアパレル小売ブランドです。同社ではモバイル アプリにチャットボットを搭載し、オンライン上だけでなく店舗でも、お客様のさまざまな質問に対応しています。現在、一部の会員向けにサービスを提供しており、ショッピングをより楽しく、シンプルにするこのチャットボットは、ユーザーの 40 % が毎週利用しています。

GCP Natural Language AI
Google の機械学習を使用して非構造化テキストから分析情報を引き出す。
Natural Language API は、テキストから構文、エンティティ、感情を検出し、テキストを事前定義された一連のカテゴリに分類します

GCP AutoML Natural Language
自社のウェブサイトに問い合わせフォームがあるとします。このフォームから毎日多くのメッセージを受け取ります。その多くはなんらかの方法で対応可能ですが、すべてのメッセージが一斉に届き、異なる従業員がいろいろなタイプのメッセージを処理するため、メッセージへの対応が遅れがちです。自動化されたシステムによってメッセージを分類し、適切な担当者が適切なコメントを見られるようになれば、非常に効率的です。

BigQuery Authorized view
利用者に対して ビューへのアクセス権限を与える が ビューの元となるテーブル自体へのアクセス権限は与えない ことにより、アクセス制御を楽にしたり、見せるデータの粒度を制御したりできる機能です。

BigQuery サイドインプット
Apache Beamでは、データ分析のためのエンリッチメントを行う際には、サイドインプットパターンが推奨されています。

Datastore は、大規模な構造化データに対して可用性の高いアクセスを必要とするアプリケーションに最適です。Datastore は、次のようなタイプのすべてのデータを保存、クエリする目的で使用できます。
- 小売店向けにリアルタイムな在庫と商品の詳細を提供する商品カタログ
- ユーザーの過去の行動と好みに応じてカスタマイズされたエクスペリエンスを提供するユーザープロフィール
- ある銀行口座から別の口座への送金など、ACID プロパティに基づくトランザクション

サブスク
定期購読など定期の意味合い


Dataprocはバックアップのmysqldumpを利用してデータ分析をおこなうために最適なサービスです。
Dataproc は、Apache Spark、Apache Flink、Presto をはじめ、30 以上のオープンソース ツールやフレームワークを実行するための、フルマネージドでスケーラビリティの高いサービスです。
Dataproc を使用すれば、データレイクのモダナイゼーション、ETL、安全なデータ サイエンスを、Google Cloud と完全に統合された極めてスケーラブルな環境で、低コストで実現できます。
ダンプしたファイルをCloud Storageに保存することで、Dataprocにインポートをすることが可能になります。


アドホック
特定の、特別の 限定目的のための

Cloud Bigtableは、最大 99.999% の可用性で大規模な分析ワークロードにも運用ワークロードにも対応できる、フルマネージドでスケーラブルな NoSQL データベース サービスです。
Cloud Bittableでは、センサーデータなどの時系列データの保存にも適しています。
行数が多く（背が高く）カラム数の少ない（幅の狭い）テーブルでは、1行あたりのイベント数が少なく、1つのイベントだけということもあり得ますが、背が低く幅の広いテーブルでは、1行あたりのイベント数が多くなります。
時系列データには、一般的に背の高いテーブルと幅の狭いテーブルを使用する必要があります。
これは、1 行に 1 つのイベントを格納することで、データに対するクエリの実行が容易になるためです。
ナローテーブル = 縦に長い
ワイドテーブル = 横に長い


Cloud DLPは、Cloud Storage、BigQuery、Cloud Datastoreの機密データのスキャンと分類をネイティブにサポートし、ストリーミングコンテンツAPIにより、追加のデータソース、カスタムワークロード、アプリケーションへのサポートを可能にします。
クラウドデータロスプリベンション（DLP）は、データセキュリティとプライバシーのレイヤーを追加してデータワークロードに組み込むことにより、機密データを保護することができます。


ハイブリッドクラウドとは、相互に情報を共有し、特定のビジネスまたは組織向けに統一された一連のアプリケーションを実行する 2 つ以上のコンピューティング環境を組み合わせたものです。次のような環境が含まれます。
1つ以上のプライベートクラウドと 1 つ以上のパブリッククラウド
2つ以上のプライベートクラウド
2つ以上のパブリッククラウド
1つ以上のクラウドに接続された 1 つのベアメタル (物理ハードウェア) 環境または仮想環境

シャーディングとは
シャーディングとはデータベースの負荷分散方法の1種で、水平分割とも呼ばれています。 同じテーブルを複数のデータベースに用意し、1つのテーブルに保存していたレコードを分散する事で各データベース内に保持されるレコードの量をへらす負荷分散の方法です。処理速度が遅いブロックチェーンなどにも使われていて今注目されている技術です。

パーティショニングは、データベースにおけるテーブル内のデータを分割して保持する機能です
パーティショニングは、データの特性や利用目的に応じて分割条件の設計が必要です。データはその条件に従って分割したテーブルに格納されますが、アプリケーションからは1つのテーブルとして扱うことができます。パーティショニングのイメージを以下に示します。

ロジスティク回帰
ロジスティック回帰分析は、いくつかの要因（説明変数）から「2値の結果（目的変数）」が起こる確率を説明・予測することができる統計手法です。
2値とは、試験の合格／不合格のように答えが2つしかない値のことを言います。


線形回帰は、別の関連する既知のデータ値を使用して未知のデータの値を予測するデータ分析手法

リカレントニューラルネットワーク (Recurrent Neural Network: RNN) は、過去の情報を利用して現在および将来の入力に対するネットワークの性能を向上させる、ディープラーニングネットワーク構造です。RNN の特徴は、ネットワークに隠れ状態とループが含まれる点です。ネットワークにループ構造を用いると、過去の情報を隠れ状態で保存し、シーケンスで処理することができます。


ニューラルネットワークとは、層状構造が人間の脳内にあるニューロンのネットワーク構造に類似した数理モデルです。ニューロンと呼ばれる相互に結合する処理要素を特徴としており、出力機能を生成します。ニューラルネットワークは、入力層と出力層で構成されており、その多くには隠れ層があります。この隠れ層は、入力を出力層で使用できるものに変換するユニットで構成されています

「回帰分析」は、結果となる数値と要因となる数値の関係を調べて、それぞれの関係を明らかにする統計的手法です。このとき、要因となる数値を「説明変数」、結果となる数値を「被説明変数」といい、「説明変数」が1つの場合を「単回帰分析」、複数の場合を「重回帰分析」といいます。
単回帰単回帰の計算式
y=a+bx
重回帰重回帰の計算式
y= a+b1x1+b2x2P+....bnxn
の式（回帰式）で表されます。

プリエンプティブ方式は、プリエンプションとも呼ばれ、実行中のタスクを中断しながら、別のタスクにCPUを割り当てて処理を行う方式です

プリエンプティブル VM インスタンスは、標準 VM の料金よりもはるかに低価格（60～91% 割引）で利用できます。
ただし、他のタスクがリソースを再利用する必要がある場合、Compute Engine がこのインスタンスを停止（プリエンプト）する可能性があります。

訓練データ (train_data)
モデルが賢くなるために使うデータ

検証データ (validation_data)
ハイパーパラメータを調整するために使うデータ

テストデータ (test_data)
学習済モデルの汎用性を評価するために使うデータ

汎化能力: 未知のデータ(訓練に使ってないデータ)に対する正しい値を予測する能力。

過剰適合: 訓練データはめっちゃ正確に予測できるけど新しいデータはてんでダメという状態。

適合不足: 訓練データすらちゃんと予測できてないという状態。

非正規形
正規化がまったく行われておらず、1行の中に複数の繰り返し項目が存在するようなテーブルは非正規形と呼びます。
イメージはエクセルで縦に結合したり同じカラムが複数あって横に長くなっていること


Cloud Dataprep は Google Cloud （GCP）に内包されているデータクレンジングサービスです。構造化データと非構造化データを視覚的に探索し、簡単にクレンジング処理を行うことができます。
データクレンジングとは、その名前の通り「データをクレンジング（洗浄）すること」を意味する言葉です。データクリーニングという名称が使われることもあります。つまり、自社が保有するデータを綺麗な形に整えることがデータクレンジングの目的です。
入力フォーマット
Cloud Dataprep への入力は以下のフォーマットに対応しています。
prep = 準備

CSV
Excel
JSON
Plain Text
Avro
BigQuery
UTF

出力フォーマット
Cloud Dataprep からの出力は以下のフォーマットに対応しています。

CSV
JSON
Avro



Pub/Subでは、一貫したスループットが維持されているのであるならば、ある期間中の処理されていないメッセージや、サブスクリプションされたメッセージ数は一定になります。
それらの値が増加することは、パフォーマンスに関する問題が発生しているということになるため、アラートを設定することが有効です。また、一定の処理をし続けているコンピューティングリソースは、インスタンス / ストレージ / 使用済みバイトも定常的になると考えられます。
それらの値が減少するということは、コンピューティングリソースがメッセージの処理を十分に行えていないということになるため、減少を検知するアラートを設定することが有効です。
Pub/Sub は、非同期のメッセージング サービスです。
イベントを生成するサービスと、イベントを処理するサービスを分離します。
メッセージ指向のミドルウェア、またはストリーミング分析用のイベントの取り込みと配信のパイプラインとして使用できます。

Apache KafkaもPub/Subと同様のメッセージングソリューションで、トピックベースで過去のデータに遡ることができます。
しかし、Pub/Subは最大で30日間のデータ保持が可能であり、メッセージの順序指定も可能であります。
更に、Pub/Subはマネジメントサービスのため、インフラストラクチャの管理が不要です。
一方で、KafkaはGoogle Cloud上でカスタムVMによるホスティングが必要です。



Cloud SQL インスタンスは高可用性（HA）構成をとることができます。
インスタンスまたはゾーンで障害が発生した場合、永続ディスクはスタンバイ インスタンスにアタッチされ、新しいプライマリ インスタンスになります。
HA 構成は「クラスタ」とも呼ばれ、データの冗長性を確保します。
リージョン インスタンスはプライマリ インスタンスとスタンバイ インスタンスで構成されます。
各ゾーンの永続ディスクへの同期レプリケーションにより、トランザクションが commit されたとしてレポートされる前に、プライマリ インスタンスへの書き込みのすべてが両方のゾーンのディスクに複製されます。
インスタンスまたはゾーンで障害が発生した場合、永続ディスクはスタンバイ インスタンスにアタッチされ、新しいプライマリ インスタンスになります。
ユーザーは新しいプライマリに再転送されます。
このプロセスは、フェイルオーバーと呼ばれます。

Cloud SQLは、最大64個のプロセッサーコアと400GB以上のRAMを追加することで簡単にスケールアップでき、最大30TBのストレージをサポートします。

Dataflowにおいて、非グローバルウィンドウ関数もしくは非デフォルト関数を使用すると、エラーが発生する。
今回のケースであればグローバルウィンドウ関数を使用する必要があります。


Dataflowジョブは、二つの方法で停止することが可能です。
- ジョブをキャンセルする：
この方法は、ストリーミング パイプラインとバッチ パイプラインの両方に適用されます。ジョブをキャンセルすると、Dataflow サービスはバッファデータなどのデータの処理を停止します。
- ジョブをドレインする：
この方法は、ストリーミング パイプラインにのみ適用されます。ジョブをドレインすると、Dataflow サービスはバッファ内のデータの処理を完了すると同時に、新しいデータの取り込みを中止できます。
今回の場合は、Drainオプションを使用することで、バッファ内のデータ処理を確実に終了し、新しいパイプラインに切り替えることが可能です。

Dataflow は Google Cloud(GCP)に内包されている ETL ツールであり、サーバーレスかつフルマネージドのデータ処理サービスです。
Dataflow は「 Apache Beam （オープンソースのフレームワーク）」で構築されたパイプライン処理を実行できるプラットフォーム

ETL とは？
ETL とは「 Extract （抽出）、 Transform （変換）、 Load （書き出し）」の略であり、企業内のあらゆるシステムからデータを抽出し、共有する機能を搭載したツールです。

サブスクライバーとは、メール等での定期的な案内の送信を承諾しているユーザーのこと


BigtableはNoSQL型のデータベースです。
パフォーマンスに影響を与える可能性がある要因を正確に監視することで、スケールアップを適切に行うことができます。
書き込み操作レイテンシーは、Bigtableのパフォーマンスを表すメトリクスになります。
このメトリクスが継続的に増加しているということは、既存のキャパシティーでは書き込み処理を維持することができないということです。
ストレージ使用率も重要なメトリクスです。
Bigtableのストレージ容量は、ストレージ タイプとクラスタ内のノード数によって決まります。
クラスタに保存されるデータ量が増加すると、Bigtable はクラスタ内のすべてのノードにデータを分散してストレージを最適化します。
データを継続的に保存し続けるためには、使用率が増大していることはいち早く検知する必要があります。
リアルタイム系に強い　スケールもできる

データセットを使用した教師あり学習による顔認識はニューラルネットワークの一種である畳み込みネットワーク (CNN：Convolutional Neural Network)によって実現可能です。
CNNは画像認識に適した手法です。
ディープラーニングの研究の中で最も進められている画像認識、物体検出、領域推定などの画像分野で活用されています。

高速のネットワーク接続を使用している場合は、gsutil -m（マルチスレッド / マルチ処理）オプションを利用することで、大量のファイルを迅速に転送できます。
ただし、一部のファイルのダウンロードが失敗していても、gsutil ではどのファイルが正常にダウンロードされたかを追跡しません。
たとえば、マルチスレッド転送を利用して 100 ファイルをダウンロードし、そのうち 3 ファイルのダウンロードが失敗した場合、どの転送が失敗したかを判別して転送を再試行する処理は、スクリプト側で行う必要があります。
こうしたケースは、前述のように定期的にチェックと実行を行うことで対応できます。


もう一つの方法は、複数のファイルをアーカイブし一つのファイルにまとめることです。
確かにgsutilで直接tarを使うことはできませんが、Cloud Storageにtarファイルをロードし、LinuxでCompute Engineインスタンスにファイルを移動し、tarでファイルを分割してCloud Storageにコピーし直すことが可能です。
多くのファイルを大きなtarでバッチ処理することで、Cloud Storageのスループットが向上する。


Dataproc は、Apache Hadoop および Hadoop 分散ファイル システム（HDFS）と統合されています。
DataprocとGCSをGoogle Cloud Storageのコネクタで接続すると、クラスタの寿命が来た後もデータを保存することができます。
Dataproc はストレージに Hadoop 分散ファイル システム（HDFS）を使用する。
また、HDFS 互換の Cloud Storage コネクタが自動的にインストールされるため、HDFS と並行して Cloud Storage も使用できます。
クラスタに対してデータの移動を行うには、HDFS や Cloud Storage へのアップロードとダウンロードを使用する。

グローバルで発生する入札イベントをスケーラブルな方法で集約する方法が必要です。
Cloud Pub/Subでメッセージを発行し、Dataflowで消費することで、イベント発生時のタイムスタンプに基づいて、メッセージをデキューすることが可能になります。
また、他のソリューションと比べてもスケーラブルでコスト効率が良い方法です。

重複排除は一般に、システムと BigQuery 間のネットワーク エラーや BigQuery の内部エラーといった特定のエラー状態でストリーミング挿入の状態を判断する方法がない分散システムでの再試行シナリオで必要です。
一方で、BigQuery の重複排除はベスト エフォート型であり、データの重複がないことを保証するメカニズムとしての使用には適していません。
さらに、データの高い信頼性と可用性を保証するために、BigQuery はベスト エフォート型の重複排除の品質を低下させる可能性があります。
ストリーミングの実行後に重複行が残らないようにするには、次の手動プロセスを使用する。
- テーブル スキーマ内の列として insertId を追加し、各行のデータに insertId 値を含めます。
- ストリーミングが停止した後に、クエリを実行して重複をチェックする。
- 重複を排除するには、次のクエリを実行する。宛先テーブルを指定し、サイズの大きい結果を許容し、結果のフラット化を無効にする。

#standardSQL

SELECT
* EXCEPT（row_number）
FROM （
SELECT
*,
ROW_NUMBER（）
OVER （PARTITION BY ID_COLUMN） row_number
FROM
TABLE_NAME
）
WHERE
row_number = 1


ODBC
Open Database Connectivity
アプリケーションソフトがデータベース管理システム（DBMS）などに接続し、データの取得や書き込み、操作などを行う方法の標準を定めたもの


BigQuery標準SQLクエリではレガシーSQLで定義されたビューを参照することができません。
DBC接続で接続するために、標準SQLを使用してevents_partitionedテーブル上に新しいビューを作成する必要があります。
また、ODBCドライバはこの際にBigQueryのロールが必要になります。

確認応答期限が切れる前にメッセージの確認応答を行わないと、Pub/Sub によってメッセージが再送信されます。
その結果、Pub/Sub によって重複するメッセージが送信されることがあります。
Google Cloud のオペレーション スイートを使用して、expiredレスポンス コードで確認応答オペレーションをモニタリングし、この状態を検出する。
このデータを取得するには、確認応答メッセージ オペレーション指標を選択し、response_code ラベルでグループ化するかフィルタする。


データセット レベルの権限により、特定のデータセット内のテーブル、ビュー、テーブルデータにアクセスできるユーザー、グループ、サービス アカウントが決まります。
たとえば、あるユーザーに特定のデータセットに対する bigquery.dataOwner Identity and Access Management（IAM）ロールを付与した場合、そのユーザーはそのデータセット内のテーブルとビューを作成、更新、削除できます。



データセットは、特定のプロジェクト内に含まれています。データセットは、テーブルとビューへのアクセスを整理して制御するために使用される最上位のコンテナです。テーブルまたはビューはデータセットに属していなければなりません。したがって、データを BigQuery に読み込む前に、1 つ以上のデータセットを作成する必要があります。


BigQuery にデータを読み込んだ後、Cloud Storageなどに、さまざまな形式でデータをエクスポートできます。
BigQuery は最大 1 GB のデータを 1 つのファイルにエクスポートできます。
1 GB を超えるデータをエクスポートする場合は、データを複数のファイルにエクスポートする必要があります。
データを複数のファイルにエクスポートすると、さまざまなサイズのファイルになります。


クラスタ化
クラスタリングとは、同じ構成の複数のコンピュータを相互接続し、外部に対して全体で一台のコンピュータであるかのように振る舞わせること

クラスタリングは、フィルタ句を使用するクエリやデータを集計するクエリなど、特定のタイプのクエリのパフォーマンスを向上させることができます。
クエリジョブまたは読み込みジョブによってデータがクラスタ化テーブルに書き込まれると、BigQuery はクラスタリング列の値を使用してデータを並べ替えます。
これらの値は、BigQuery ストレージ内の複数のブロックにデータを整理するために使用されます。
クラスタリング列に基づいてデータをフィルタする句を含むクエリを送信すると、BigQuery は並べ替えられたブロックを使用して不要なデータのスキャンを省略します。

Dataproc クラスタを作成するときは、クラスタを設定した直後に Dataproc が Dataproc クラスタ内のすべてのノードで実行する初期化アクションとして実行可能ファイルまたはスクリプトを指定できます。
初期化アクションは、ジョブの実行時に依存関係をインストールしなくてもジョブをクラスタに送信できるよう、Python パッケージのインストールなど、ジョブの依存関係を設定するために多く用いられます。


シンクは Cloud Logging に入ってきたログの振り分けをするコンポーネントです。

API を通じて Cloud Logging に入ってきたログは、シンクによって宛先であるログバケットや BigQuery などに振り分けられます。

シンクを作成した際、振り分け先が「そのシンクが所属するプロジェクトのログバケット 以外 」だった場合、 書き込み ID (Writer Identity) と呼ばれるサービスアカウントが生成されます。

書き込み ID はシンクを作成するごとに一意に生成されます。

シンクにはレベルがあり、プロジェクト、フォルダ、組織レベルと言ったものをつくれる

集約シンクは、組織またはフォルダに含まれる Google Cloud リソースからのログエントリを結合してルーティングします。
たとえば、組織に含まれるすべてのフォルダの監査ログエントリを集約し、Cloud Storage バケットに転送できます。
集約シンク機能がないと、シンクは、シンクが作成された正確なリソース（Google Cloud プロジェクト、組織、フォルダ、請求先アカウント）からのログエントリのルーティングに限定されます。


Cloud Spanner データベースは、1 つ以上のテーブルを含むことができます。
テーブルは行、列、値という構造を持ち、主キーを備えている点で、リレーショナル データベース テーブルに似ています。
主キーを選択する上で重要な点は、ホットスポットを回避するという点です。
単調増加する値やエポックタイムなどは、ホットスポットを発生させる可能性があるため不適切です。
代わりに、キーのハッシュ値やUUIDなどのランダムな値を用いることは、ベストプラクティスです。

BigQueryのDMLは、1つのジョブでテーブル内の任意の数の行を挿入、更新、削除することをサポートしています。

2020年3月までは、DML(delete merge upudateなど)の１日あたりの上限がありましたが、それ以降は上限が撤廃されました。
これによって、今回のような1時間に数千回データ更新がある場合でもDMLを用いてパフォーマンスを最大化することが可能です。

Cloud Monitoringでは、ネットワーク接続、ディスクID、レプリケーションの状態などのカスタムメトリクスはデフォルトで収集することができません。
従って、オーバーヘッドの少ない方法で、VMからカスタムメトリクスを収集するためのツールをインストールする必要があります。
Google Cloudでは、OpenCensus(調査)を使ったカスタムメトリクスの収集が推奨されています。

エンティティアナライズ
エンティティ分析は、指定されたテキストに既知のエンティティ（著名人、ランドマークなどの固有名詞）が含まれていないかどうかを調べて、それらのエンティティに関する情報を返します。

IoTデバイスから送信されるデータは非構造データであるため、NoSQLデータベースを選択する必要があります。

この要件を満たすのは、HBase, MongoDB, Cassandraです。

HBaseは、Googleのビッグテーブルに似たNoSQLデータモデルで、膨大な量の構造化データへの迅速なランダムアクセスを実現するために設計されました。
Hadoop File System （HDFS）が提供するフォールトトレランスを利用しています。
HDFSはHadoopエコシステムの一部であり、Hadoop File System内のデータに対してランダムなリアルタイムリード/ライトアクセスを提供する。
HDFSには、直接またはHBaseを介してデータを格納することができます。
データ消費者は、HBaseを使用してHDFSのデータをランダムに読み取り、アクセスする。HBaseはHadoop File Systemの上に置かれ、読み取りと書き込みのアクセスを提供する。
MongoDB Atlas は、Google のグローバルにスケーラブルで信頼性の高いインフラストラクチャ上で、フルマネージド サービスを提供する。
Atlas を使用すると、UI を数回クリックするか API 呼び出しを実行するだけでデータベースを簡単に管理できます。
移行は簡単で、グローバル クラスタなどの高度な機能を備え、世界中のどこにいても低レイテンシの読み取りおよび書き込みアクセスが可能です。
Apache Cassandraは、オープンソースのNoSQL分散型データベースで、パフォーマンスを損なうことなく拡張性と高可用性を実現できます。
コモディティ・ハードウェアやクラウド・インフラ上で直線的なスケーラビリティと実証済みのフォールトトレランスを実現し、ミッションクリティカルなデータに最適なプラットフォームとなります。

Apache Beam SDK または Dataflow SQL ストリーミング拡張機能で次のウィンドウを設定する。
- タンブリング ウィンドウ（Apache Beam では固定ウィンドウ）
- ホッピング ウィンドウ（Apache Beam ではスライディング ウィンドウ）
- セッション ウィンドウ

タンブリング ウィンドウとは、データ ストリームを重なりなく分ける一定の時間間隔を表する。
たとえば、30 秒のタンブリング ウィンドウに設定すると、タイムスタンプ値が [0:00:00-0:00:30] の要素が最初のウィンドウに表示されます。
2 番目のウィンドウには、[0:00:30-0:01:00] のタイムスタンプ値を持つ要素が表示されます。

ホッピング ウィンドウとは、データ ストリーム内の一定の時間間隔を表する。
タンブリング ウィンドウは重なりませんが、ホッピング ウィンドウは重なることがあります。
たとえば、ホッピング ウィンドウが 30 秒ごとに開始し、1 分間のデータとウィンドウを持つ場合があります。
ホッピング ウィンドウの開始間隔はピリオドといいます。

セッション ウィンドウには、別の要素とのギャップ期間に存在する複数の要素が含まれます。



トレーニングデータセットに対する性能とテストデータセットに対する性能に応じて、モデルの学習状況の問題は大きく２つに分類されます。
- 過剰適合（overfitting）
トレーニングデータセットに対する性能が良いが、テストデータセットに対する性能が低い状態です。
実際の問題にモデルを使用した際に、思ったような性能が得られない可能性があるため、モデルに以下のようなチューニングを加える必要があります。
-- 正則化の制約を増やす
-- ドロップアウトを増やす
-- 次元圧縮（特徴量の数を減らす）
-- （ニューラルネットワークの場合）レイヤーを減らして単純なモデルにする
-- 学習率を小さくする



- 適合不足（underfitting）
トレーニングデータセットに対する性能も、テストデータセットに対する性能も低い状態です。
モデルのチューニング等を行ってもこの状態が改善されない場合は、データセット自体を増やす必要があります。
データセットはマニュアルでのデータセットの追加や、データ拡張による追加が有効です。
また、特徴量が少なすぎることにより、現象を正しくとらえられていない可能性もあります。
この場合は、新たな特徴量を追加する、特徴量エンジニアリングによって特徴量を合成する、といった対処が必要です。

Cloud Storageへのデータ転送の場合は、Storage Transfer Serviceが適切な選択肢です。
Storage Transfer Serviceは、クラウドまたはオンプレミスのソースからデータを転送する安全で低コストのサービスです。
Storage Transfre Serviceは、コードを 1 行も書かずに転送を完了することができるだけでなく、転送ステータスをモニタリングする一元化されたジョブ管理を利用できます。

プリファレンス 選好
大量の機密性の高い構造データをオンプレミスからBigQueryにロードする必要があります。
ポイントは、エクスポートするファイル形式と、転送方法です。


10TBの構造データはAvroファイルとしてエクスポートすることが最適です。
Apache Avro はデータがバイナリエンコードされる、軽量で柔軟なデータフォーマットです。
BigQuery や Apache Kafka などのビッグデータ処理基盤でしばしば使用されるフォーマットで、データ構造をリッチに表現することができ、スキーマ付きのファイルのサポートもされています。


大容量データのセキュアな転送は、Transfer Applianceが最適です。
Transfer Appliance は大容量のストレージ デバイスであり、データを Google アップロード施設にデータの転送と安全な配送をし、そこからデータは Cloud Storage またはBigQueryに移行することができます。
Google Cloudは、アプリケーションなどが別のサービスを利用する際にサービスアカウントの利用を推奨しています。
サービス アカウントは特別なタイプの Google アカウントで、Google API のデータにアクセスして認証を受ける必要がある人間以外のユーザーを表する

Cloud Key Management Service を使用すると、単一の集中型クラウド サービスで暗号鍵の作成、インポート、管理を行い、暗号化オペレーションを実行できます。
これらの鍵を使用してこれらのオペレーションを実行するには、Cloud KMS を直接使用するか、Cloud HSM または Cloud External Key Manager を使用するか、他の Google Cloud サービス内の顧客管理の暗号鍵（CMEK）を使用する。



常に生成されて書き込まれる時系列データを保存する適切なストレージを選択する必要があります。
Cloud Bigtable は、Google のフルマネージド NoSQL ビッグデータのデータベース サービスです。
Cloud BigtableをCloud Dataflowと組み合わせることで、ストリーミングのデータのオペレーションを容易に行うことができます。


CSV ファイルを BigQuery に読み込む場合は、次の点に注意してください。
- CSV ファイルはネストされたデータや繰り返しデータに対応していません。
- バイト オーダー マーク（BOM）文字を削除する。予期しない問題が発生する可能性があります。
- gzip 圧縮を使用した場合、BigQuery はデータを並列で読み取ることができません。圧縮された CSV データを BigQuery に読み込む場合は、圧縮されていないデータを読み込むよりも時間がかかります。圧縮データと非圧縮データを読み込むをご覧ください。
- 同じ読み込みジョブに圧縮ファイルと非圧縮ファイルの両方を含めることはできません。
- gzip ファイルの最大サイズは 4 GB です。
- CSV データまたは JSON データを読み込む場合、DATE 列の値に区切りとしてダッシュ（-）を使用し、YYYY-MM-DD（年-月-日）の形式にする必要があります。
- JSON または CSV データを読み込む場合、TIMESTAMP 列のタイムスタンプ値の日付部分の区切りにはダッシュ（-）を使用し、日付は YYYY-MM-DD（年-月-日）の形式にする必要があります。タイムスタンプの時間部分 hh:mm:ss（時-分-秒）には、区切りとしてコロン（:）を使用する。

BigQueryIO.read.from（）は、BigQueryからテーブル全体を直接読み取ります。
この関数は、テーブル全体をGoogle Cloud Storageの一時ファイルにエクスポートし、後でそこから読み込むことになります。
これはエクスポートジョブを実行するだけで、後のDataflowは（BigQueryからではなく）GCSから読み込むため、ほとんど計算を必要としません。
一方で、全てのデータを読み込むという性質上、時間がかかります。

data flow
パイプラインで、要素を処理できない際の原因はさまざまですが、一般的な原因はデータの問題です。
このような状況におけるアプローチの 1 つは、DoFn.ProcessElement メソッドで例外をキャッチする方法です。
例外ブロックでは、エラーをログに記録して要素を廃棄する。
ただし、これによりデータが失われ、手動処理またはトラブルシューティングのためにデータが検査されなくなります。
Google Cloudが推奨するより良い方法としては、デッドレター キュー（またはデッドレター ファイル）と呼ばれるパターンを使用することです。
DoFn.ProcessElement メソッドで例外をキャッチして、エラーを通常どおりにロギングする。
ただし、失敗した要素をドロップする代わりに、分岐出力を使用して、失敗した要素を個別の PCollection オブジェクトに書き込みます。
その後、これらの要素はデータシンクに書き込まれ、別の変換を使用して、後で検査や処理を行うことができます。

、ストリーミングデータの取り込みにCloud Pub/Subを使用し、Cloud Dataflowを用いたETL処理を実装することで、柔軟性の高いスケーラブルなパイプラインを構築することができます。


BigQueryでは、各テーブルに対してテーブルレベルのアクセスコントロールを行うことができます。

Bigtable
単一のクラスタ上で、多数の大規模読み取りを実行するバッチ分析ジョブを、読み取りや書き込みを実行するアプリケーションと並行して実行すると、大規模バッチジョブがアプリケーションのユーザーにとって処理を遅くする可能性があります。
レプリケーションでは、単一クラスタ ルーティングのアプリ プロファイルを使用してバッチ分析ジョブとアプリケーション トラフィックを異なるクラスタにルーティングできるため、バッチジョブがアプリケーションのユーザーに影響を与えることはありません。


Cloud Audit Logs は Google Cloud が提供するログの集まりで、Google Cloud サービスの使用に関連する運用上のアクセス等の記録を把握することができます。
BigQueryを用いることで、Cloud Audit Logsを収集して解析することが可能になります。

データに存在するラベルに対しては教師あり学習を利用することができます。
一方で、存在しないラベリング（不正検知、特定のセグメンテーション）を推測するためには教師なし学習が必要です。

メトリクス（メトリック）とは、定期的にシステムのヘルス情報やパフォーマンス情報を取得し、測定値をグループ化したものです。

ハイパーパラメータ（英語：Hyperparameter）とは機械学習アルゴリズムの挙動を設定するパラメータをさします。少し乱暴な言い方をすると機械学習のアルゴリズムの「設定」です。
この設定（ハイパーパラメータの値）に応じてモデルの精度やパフォーマンスが大きく変わることがあります。例えば男女を分類するモデルを構築していた場合、特に調整を行わずに初期設定のままモデリングを行なった結果、最初は90%の正解率を得ることができたとします。90%の精度では使い物にならないと上司に怒られたので、ハイパーパラメータ（モデルの設定）を調整したところ93%へ改善することがあります。ハイパーパラメータチューニング自動化の動きもありますが、一般的には「人間」が「手動」で調整を行なっていきます。
近年、日本でも大人気のKaggleもハイパーパラメータのチューニングは必須のスキルです。Kaggleのようなデータ分析競技では0.01%の差で順位を争うことも少なくありません。モデルのハイパーパラメータを適切に調整してスコアを伸ばしていくのはKaggleの基本技です。


グローバルスケールで強力な一貫性を持つデータベースサービスを利用する必要があります。
Cloud Spannerは無制限のスケーリング、強い整合性、最大 99.999% の可用性を備えたフルマネージド リレーショナル データベースです。
グローバルなトランザクション整合性、高可用性のための自動の同期レプリケーション、2 つの SQL 言語（Google 標準 SQL（拡張機能を含む ANSI 2011）と PostgreSQL）が含まれています。

Parquet は効率的なカラム型ファイル形式であり、Spark でアプリケーションの実行に必要なデータのみを読み取ることができます。
SparkジョブでParquetファイルを使用する場合、ファイルサイズの目安は1GBと言われています。

Compute Engine インスタンスで GPU または CPU を使用して機械学習ワークロードを実行する場合があります。

一般的に、次のガイドラインに基づいてワークロードに最適なハードウェアを決定できます。
CPU
- 最大限の柔軟性を必要とする迅速なプロトタイピング
- トレーニングに時間がかからない単純なモデル
- 実際のバッチサイズが小さい小規模なモデル
- C++ で記述されたカスタム TensorFlow 演算が多くを占めるモデル
- ホストシステムの使用可能な I/O またはネットワーク帯域幅によって制限が課せられるモデル

GPU
- ソースが存在しないモデルまたはソースを変更するのが煩雑すぎるモデル
- CPU 上で少なくとも部分的に実行しなければならない多数のカスタム TensorFlow 演算を使用するモデル
- Cloud TPU で利用できない TensorFlow 演算を使用するモデル（利用可能な TensorFlow 演算のリストをご覧ください）
- 実際のバッチサイズが大きい中～大規模なモデル

TPU
- 行列計算が多くを占めるモデル
- メインのトレーニング ループ内にカスタム TensorFlow 演算がないモデル
- トレーニングに数週間または数か月かかるモデル
- 実際のバッチサイズが非常に大きい非常に大規模なモデル


クォータとは、クラウドプロジェクトが使用できる特定の共有 Google Cloud リソースの量を制限するもので、ハードウェア、ソフトウェア、ネットワークコンポーネントなどが含まれます。

Google Cloudが推奨するBigQueryへのインポートの方法は、次のBigQueryのMERGEステートメントを使用して、別のテーブル（新着情報が保管されている）の内容に基づいて既存テーブルのバッチ更新を実行する方法です。

MERGE dataset.Inventory T
USING dataset.NewArrivals S
ON T.ProductID = S.ProductID
WHEN MATCHED THEN
UPDATE SET quantity = T.quantity + S.quantity
WHEN NOT MATCHED THEN
INSERT (ProductID, quantity) VALUES (ProductID, quantity)

Dataprocでは、Apache Spark 用の BigQuery コネクタを使用すると、データ サイエンティストは、BigQuery のシームレスでスケーラブルな SQL エンジンの能力と Apache Spark の機械学習機能を融合できます。
Cloud SQL は、Google Cloud Platform 上のリレーショナル データベースの設定、維持、運用、管理を支援するフルマネージドのデータベース サービスです。
BigQueryとは異なりトランザクションを記録するためのSQLデータベースとして使用が可能です。
また、Cloud SQL インスタンスには、あらゆるアプリケーションからアクセスできます。
App Engine、Compute Engine、Google Kubernetes Engine、自社のワークステーションのいずれからでも、簡単に接続でき、もちろんBIツールとの接続も可能です。

フォールトトレランスとは、機器やシステムなどが持つ性質の一つで、構成要素の一部が故障、停止などしても予備の系統に切り替えるなどして機能を保ち、稼動を続行できること。また、そのような仕組みや設計方針。

Apache Parquet は、効率的なデータの保存と検索のために設計された、オープンソースの列指向データファイル形式です
列方向に連続してデータを格納する方式で、列単位でデータを取り出す分析用途に向いています

Pigは大規模なデータセットを分析するためのプラットフォームです。
Hadoop上に構築されており、プログラミングの容易さ、最適化の機会、拡張性を提供する。
Pig Latinはリレーショナルデータフロー言語であり、Pigのコアなコンポーネントの1つです。
データパイプラインの構築の際には、いくつかの理由からSQLよりもPig Latinの方がより優れた選択になります。
- Pig Latinでは、パイプラインの開発者が、パイプラインのどこにデータをチェックポイントするか決めることができます。
- Pig Latinでは、オプティマイザに頼らず、特定の演算子の実装を直接選択することができます。
- Pig Latinはパイプラインの分割をサポートする。
- Pig Latinでは、開発者がデータパイプラインのほとんどどこにでも独自のコードを挿入することができます。

Dataproc は、Apache Hadoop および Hadoop 分散ファイル システム（HDFS）と統合されています。
この際、ローカルHDFSストレージを用いることで、パフォーマンスを高めることができる場合があります。

ローカルHDFSストレージは、以下のような場合に有効なオプションです。
- ジョブで多くのメタデータ操作が必要な場合。例えば、数千のパーティションやディレクトリがあり、各ファイルのサイズが比較的小さい場合。
- HDFSのデータを頻繁に変更したり、ディレクトリの名前を変更したりする場合。クラウドストレージのオブジェクトは不変なので、ディレクトリ名の変更は、すべてのオブジェクトを新しいキーにコピーし、その後削除することになるため、高価な操作となります。
- HDFSのファイルに対してappend操作を多用する場合。
- 重いI/Oを伴うワークロードがある場合。例えば、次のようなパーティション化された書き込みを多く行っている場合。
-- spark.read().write.partitionBy(...).parquet("gs://")のようなパーティションによる書き込みが多い場合。
- レイテンシーに特に敏感なI/Oワークロードがある場合。たとえば、ストレージ操作ごとに1桁のミリ秒のレイテンシが必要な場合です。



Dataprocのようなバッチの場合は、コンピューティングリソースが時間課金という特性を活かして、水平スケーリングを積極的に活用するべきです。
つまり、一つのコンピューティングリソースでワークロードを処理する場合も、複数のリソースでワークロードを処理する場合も原理的には変わらないという性質を利用します。
また、ワーカーノードには、プリエンプティブルなインスタンスを用いることで、コスト削減も実現できます。


グレイスフル・デグラデーション（graceful degradation）とは、システムが破壊されたり操作不能になったりした場合に、システムダウンを発生させずに限られた機能を維持できるように設計する手法です。


ラップトップ「ノートパソコン」の別の呼び名。本体に画面とかキーボードがくっついていて、パッと見で持ち運びできそうなパソコン


Dataflow と KafkaIO を使用してメッセージのストリーミングパイプラインを構築することが可能です。
Dataflow を使用して Google Cloud の内部でメッセージを処理します。
Dataflowにネイティブに備わっているウィンドウ関数を使用することで、メッセージ数に応じたアクションを行うことが可能です。
ウィンドウ関数は、制限なしコレクションを論理的な要素、つまりウィンドウに分割します。
スライディングタイム ウィンドウは、データ ストリーム内の一定の時間間隔を表すこと



BigQuery のようなデータ ウェアハウスでは、位置情報が非常によく使われます。
地理情報を含むGeoJSON形式をサポートしておりかつ、可視化ツールとネイティブな連携が可能なストレージサービスを選択する必要があります。

データベースの障害が発生した際にリクエストを一定間隔で送り続けると、負荷増大による更なる障害につながる可能性があり、これを回避する必要があります。
指数バックオフを使用すると、アプリケーションでデータベースに接続できないときに、アプリケーションによって応答しない数の接続リクエストが送信されるのを防ぎます。
この再試行は、最初に接続するときや、プールから最初に接続を取得したときにのみ有効です。
トランザクションの途中でエラーが発生した場合、アプリケーションはトランザクションの最初から再試行する必要があります。
そのためプールの構成が適切でも、接続が失われるとアプリケーションにエラーが表示されることがあります。

Dataflowによって順序が担保されない場合、タイムスタンプデータとウォーターマークを使用してアプリケーション側で順序を保証する必要があります。

機械学習モデルを正しく評価するためには、学習データとは異なるデータを用いたテストでの性能を評価する必要があります。
テストでの性能のことを汎化はんか性能といい、この性能が実問題での性能であると考えることができます。
- 過剰適合（overfitting）
トレーニングデータセットに対する性能が良いが、テストデータセットに対する性能が低い状態です。
実際の問題にモデルを使用した際に、思ったような性能が得られない可能性があるため、モデルに以下のようなチューニングを加える必要があります。
-- ドロップアウトを増やす
-- 正則化の制約を増やす
-- 次元圧縮（特徴量の数を減らす）
-- （ニューラルネットワークの場合）レイヤーを減らして単純なモデルにする
-- 学習率を小さくする

- 適合不足（underfitting）
トレーニングデータセットに対する性能も、テストデータセットに対する性能も低い状態です。
モデルのチューニング等を行ってもこの状態が改善されない場合は、データセット自体を増やす必要があります。
データセットはマニュアルでのデータセットの追加や、データ拡張による追加が有効です。
また、特徴量が少なすぎることにより、現象を正しくとらえられていない可能性もあります。


Cloud Pub/Subで配信されるデータは、プルをするだけでなく、確認を明示的に行う必要があります。
この処理を行わない場合、再度メッセージがPub/Sub内に蓄積されてしまいます。
これによって、新しいデータを処理することができずに時間を浪費してしまいます。
Cloud Functionsのエラー処理を行うためには、
- サブスクライバのコードのエラー処理がランタイムエラーを適切に処理していない
- サブスクライバのコードは、プルをしたメッセージを確認しない

複数の特徴量から1つの特徴量を生成するためには、それらの特徴量を一定のルールに基づいて掛け合わせることが必要です。
緯度と軽度の値をパラメータに取り、それらに対して四則演算を行うことで、一つの特徴量を作成する
特徴量を増やした場合や、生成した特徴量が他に比べて重要であると分かっている場合はL1正則化を使用することが有効です。
L1正則化はL2正則化と異なり、重要でない特徴量の重みを0にするため過学習を効率よく防ぐ

教師なし学習によって行う異常検知は、異常データが正常データの集団と比較して分離ができる（＝外れ値である）という前提に立っています。
これは言い換えると、異常データの発生確率は正常データの発生確率に比べて少なく、正常データと比較して既存の観測されている異常データと新たな異常データが近しい特徴を持つ、ということになります。
一方で、教師あり学習を行うことができるデータは、すでに正常/異常のラベルがついており、モデル作成可能な比率で正常/異常のデータが一定数存在しています。

Datastoreの柔軟なスキーマにより、アプリケーションの新機能をサポートするために新しいプロパティを追加するなど、時間の経過とともにユーザプロファイルの構造を変化させることができます。
スキーマの変更はダウンタイムなしで行われ、ユーザー数が増加してもパフォーマンスが低下することはありません。


















